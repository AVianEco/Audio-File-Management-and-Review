test_plot<- ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = "dodge") +
geom_bar(aes(y = avg_sampling_frequency), stat = "identity", fill = "orange", position = "dodge") +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_minimal()
test_plot
test_plot<- # Plotting mean file size and mean sampling frequency by site ID
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.9)) +
geom_bar(aes(y = avg_sampling_frequency), stat = "identity", fill = "orange", position = position_dodge(width = 0.9), width = 0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_minimal()
test_plot
# Find mean file size and sampling frequency by site
size_check <- file_track %>%
group_by(site_ID) %>%
summarise(avg_file_size_bytes = mean(file_size_mb)*1000,
avg_sampling_frequency = mean(sampling_frequency))
#add a column to check if site recordings match programmed sampling frequency
size_check$matching_SF <- size_check$avg_sampling_frequency == programmed_SF
#view size_check
view(size_check)
# Find mean file size and sampling frequency by site
size_check <- file_track %>%
group_by(site_ID) %>%
summarise(avg_file_size_mb = mean(file_size_mb),
avg_sampling_frequency_kHz = mean(sampling_frequency)/1000)
#add a column to check if site recordings match programmed sampling frequency
size_check$matching_SF <- size_check$avg_sampling_frequency == programmed_SF
#add a column to check if site recordings match programmed sampling frequency
size_check$matching_SF <- size_check$avg_sampling_frequency == programmed_SF/1000
#view size_check
view(size_check)
#add a column to check if site recordings match programmed sampling frequency
size_check$matching_SF <- size_check$avg_sampling_frequency == programmed_SF/1000
rm(list = ls())
# ------Load Libraries------
library(anytime)
library(lubridate)
library(tidyverse)
library(ggplot2)
library(tcltk)
# ------INPUT AND OUTPUTS: Define File Locations and Output Name*------
# Find the file name and path to the saved file tracking CSV on your computer.
source_CSV <- file.choose()
# Find the directory where you'd like to save visualized outputs.
destination_filepath <- tk_choose.dir()
# ------Load the file------
file_track <- read.csv(source_CSV)
#-----DATA CHECKING: Check your headers*-----
# Create the list of required headers
headers_req<-c("file_name","time","date","site_ID", "file_size_mb")
# Check against your file list.
has_req<-sum(headers_req %in% colnames(file_track))
# Describe in console what columns need replacing.
if(has_req==5){
message("All required headers exist skip to DATA CHECKING: Format date and time")
} else{
missing_headers <- headers_req[!(headers_req %in% colnames(file_track))]
message(paste("You are missing some required headers, this includes: ", paste(missing_headers, collapse = ", "),
". Go to the assign required headers section and replace headers as required."))
}
# apply anydate() function to convert to standard YYYY-MM-DD format
file_track$date <- anydate(file_track$date)
#format time using parse-time:
for (i in seq_along(file_track$time)) {
if (grepl(":", file_track$time[i])) {
# Do nothing if the time is already in HH:MM:SS format)
} else {
# Remove dashes and parse time
file_track$time[i] <- gsub("-", "", file_track$time[i])
file_track$time[i] <- parse_time(file_track$time[i], "%H%M%S")
}
}
fileperday<-24 #edit this number with your own files/day estimate based off your recording schedule.
deployment_date<-ymd(20230414)
retrieval_date<- ymd(20230623)
programmed_SF<-c(10)
programmed_SF<-c(24000)
programmed_recduration<-c(10)
#Calculate number of days between dates
deployment_length <- as.numeric(difftime(retrieval_date, deployment_date, units = "days")+1)
message(paste("Your devices were deployed up to:", deployment_length, "days."))
#Calculate total possible audio recordings
est_total_files<-fileperday * deployment_length
message(paste("Based on your recording schedule and deployment length,
the total recordings possible per site are:", est_total_files, "files."))
#Count number of recordings per site
site_recs <- file_track %>%
group_by(site_ID) %>%
summarise(n_files = n())
site_recs <- site_recs%>%
mutate(percent_estimated_files = n_files/est_total_files*100)
#Sort the table lowest to highest by percent of estimated files captured.
site_recs <- site_recs %>%
arrange(percent_estimated_files)
#View the table
view(site_recs)
# Set up the plot
G1 <- ggplot(site_recs, aes(x = site_ID, y = n_files)) +
# Add the bars
geom_bar(stat = "identity", fill="#1254ab") +
# Format the plot and add labels
labs(title = "Number Recordings by Site",
x = "Site ID",
y = "Count of Total Recordings") +
theme_bw(base_size = 14) +
# Add the horizontal line and format it
geom_hline(aes(yintercept = est_total_files, linetype = "Number of Scheduled Files"),
color = "#fdee03", linewidth = 1.5, show.legend = TRUE) +
scale_linetype_manual(name = "", values = "dashed") +
# Set the fill colors and labels
scale_fill_manual(values = "#fdee03",
labels = "") +
ylim(0,(max(max(site_recs$n_files)*1.1, est_total_files))) +
theme(legend.position = "bottom", axis.text.x = element_text(angle = 90))
# Show the plot
G1
#Save the graph
ggsave(file.path(destination_filepath, "Num_Files_by_Site.png"),
plot = G1, width = 8, height = 6, dpi = 300)
#create a dataframe with all unique dates by site.
date_check <- file_track %>%
group_by(site_ID, date) %>%
summarise(file_count = n(), .groups = 'drop')
# Order by site_ID and date (ascending oldest to newest)
date_check <- date_check[order(date_check$site_ID, date_check$date),]
view(date_check)
# Plot with ggplot2
G2<- ggplot(date_check, aes(x = date, y = site_ID)) +
theme_bw() +
geom_point(aes(size = file_count, color = file_count)) +
scale_radius(range = c(2, 6)) +
scale_color_gradient2(low = "red2", mid = "goldenrod1", high = "yellow",
midpoint= mean(date_check$file_count)) +
labs(x = "Dates Active", y = "Site ID", title = "Files Captured by Date") +
guides(colour = guide_legend("Number of Files"),
size = guide_legend("Number of Files")) +
theme(legend.position = "bottom",
axis.text.x = element_text(angle = 90)) +
#you may wish to change the number of days to make the X-axis more legible*
scale_x_date(date_breaks = "2 day", date_labels = "%Y-%m-%d")
# Show the plot
G2
#Save the graph
ggsave(file.path(destination_filepath, "Number_Files_by_Date.png"),
plot = G2, width = 8, height = 6, dpi = 300)
#create a dataframe with all unique dates by site.
time_check<-file_track %>%
group_by(site_ID, time) %>%
summarise(file_count=n(), .groups = "drop")
# Order by site_ID and time
time_check <- time_check[order(time_check$site_ID, time_check$time),]
view(time_check)
# Create a vector of time values from "00:00:00" to "23:00:00"
time_values <- seq(as.POSIXct("00:00:00", format = "%H:%M:%S"),
as.POSIXct("23:00:00", format = "%H:%M:%S"), by = "hour")
# Convert the time column in your data frame to POSIXct format
time_check$time <- as.POSIXct(time_check$time, format = "%H:%M:%S")
# Plot with ggplot2
G3<- ggplot(time_check, aes(x = time, y = site_ID)) +
theme_bw() +
geom_point(aes(size = file_count, color = file_count)) +
scale_size(range = c(2, 6)) +
scale_color_gradient2(low = "yellow", mid = "seagreen1", high = "royalblue3",
midpoint= mean(time_check$file_count)) +
labs(x = "Times Active", y = "Site ID", title = "Files Captured by Time") +
guides(colour = guide_legend("Number of Files"),
size = guide_legend("Number of Files")) +
theme(legend.position = "bottom",
axis.text.x = element_text(angle = 90)) +
scale_x_time(breaks = time_values, labels = format(time_values, "%H:%M:%S"))
# Show the plot
G3
#Save the graph
ggsave(file.path(destination_filepath, "Number_Files_by_Time.png"),
plot = G3, width = 8, height = 6, dpi = 300)
# Find mean file size and sampling frequency by site
size_check <- file_track %>%
group_by(site_ID) %>%
summarise(avg_file_size_mb = mean(file_size_mb),
avg_sampling_frequency_kHz = mean(sampling_frequency)/1000)
#add a column to check if site recordings match programmed sampling frequency
size_check$matching_SF <- size_check$avg_sampling_frequency == programmed_SF/1000
#add a column to check if site recordings match programmed sampling frequency
size_check$matching_SF <- size_check$avg_sampling_frequency_kHz == programmed_SF/1000
#view size_check
view(size_check)
test_plot<-# Plotting mean file size and mean sampling frequency by site ID
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.9)) +
geom_bar(aes(y = avg_sampling_frequency), stat = "identity", fill = "orange", position = position_dodge(width = 0.9), width = 0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_minimal()
test_plot
# Set up the plot for file sizes and sampling frequency
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.9)) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = 0.9), width = 0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_minimal()
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.5)) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = 0.9), width = 0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_minimal()
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.5), width=0.5) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = 0.9), width = 0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_minimal()
# Set up the plot for file sizes and sampling frequency
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.5), width=0.5) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = 0.9), width = 0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_bw()
# Set up the plot for file sizes and sampling frequency
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.1), width=0.5) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = 0.9), width = 0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_bw()
# Set up the plot for file sizes and sampling frequency
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.5)) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = 0.5), width = 0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_bw()
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.1), width = 0.5) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = 0.9), width = 0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_bw()
# Set up the plot for file sizes and sampling frequency
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.9)) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = 0.9), width = 0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_bw()
# Set up the plot for file sizes and sampling frequency
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.8), width=0.5) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = 0.8), width = 0.3) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_bw()
# Set up the plot for file sizes and sampling frequency
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = 0.8), width=0.5) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = 0.8)) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_bw()
?position_dodge
# Set up the plot for file sizes and sampling frequency
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(), width=0.5) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge()) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_bw()
# Set up the plot for file sizes and sampling frequency
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(padding=0.1), width=0.5) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(padding=0.1),width=0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_bw()
# Set up the plot for file sizes and sampling frequency
ggplot(size_check, aes(x = site_ID)) +
geom_bar(aes(y = avg_file_size_mb), stat = "identity", fill = "skyblue", position = position_dodge(width = NULL, preserve = "total", padding=0.1), width=0.5) +
geom_bar(aes(y = avg_sampling_frequency_kHz), stat = "identity", fill = "orange", position = position_dodge(width = NULL, preserve = "total", padding=0.1),width=0.5) +
labs(title = "Mean File Size and Sampling Frequency by Site ID",
x = "Site ID",
y = "Value") +
scale_y_continuous(sec.axis = sec_axis(~., name = "Mean Sampling Frequency")) +
theme_bw()
size_check_long <- size_check %>%
pivot_longer(cols = c(avg_file_size_mb, avg_sampling_frequency),
names_to = "variable",
values_to = "value")
# ------Clear the Workspace-------
rm(list = ls())
# ------Load Libraries------
library(tidyverse)
library(tcltk)
library(tuneR)
# Find the file path to the files you want to index.
#   This will pop up a window for selection, you may have to minimize RStudio to see this window.
source_filepath <- tk_choose.dir()
# Find the file path to the files you want to index.
#   This will pop up a window for selection, you may have to minimize RStudio to see this window.
source_filepath <- tk_choose.dir()
# Find the directory where you'd like to save the modified output csv.
destination_filepath <- tk_choose.dir()
# Find the file path to the files you want to index.
#   This will pop up a window for selection, you may have to minimize RStudio to see this window.
source_filepath <- tk_choose.dir()
# Find the file path to the files you want to index.
#   This will pop up a window for selection, you may have to minimize RStudio to see this window.
source_filepath <- tk_choose.dir()
# Find the directory where you'd like to save the modified output csv.
destination_filepath <- tk_choose.dir()
# Edit the file name within the "" below to name the output csv. Leave the quotes and
# ".csv" in the output name.
output_CSV_name <-"Audio_file_tracking.csv"
device_manuf<-c("INSERT NAME OF MANUFACTURER FROM ABOVE OPTIONS")
device_manuf<-c("Wildlife Acoustics")
#list all the files
File_List<-list.files(path = source_filepath,full.names=TRUE,recursive=TRUE)
#count the number of files
num_file<-length(File_List)
#create a dataframe from the list
file_df <- data.frame(ID = 1:num_file, file_loc = File_List)
# Find the first filepath with the most subfolders, and print it in the console.
max_index <- str_count(file_df$file_loc, "/")%>%
which.max()
print(file_df[max_index,"file_loc"])
header_file_df<-c("disk","client","Year","site_ID","file_name")
#Split the columns by "/" create a new dataframe with the edited column headers.
file_df<-separate(data = file_df, col = file_loc, into = c(header_file_df), sep = "/", remove = FALSE)
#view split columns:
view(file_df)
header_file_df<-c("disk","client","Year","unit_site","file_name")
file_df<-separate(data = file_df, col = file_loc, into = c(header_file_df), sep = "/", remove = FALSE)
#view split columns:
view(file_df)
Splitting the site_ID column into unit_ID and site_name
unit_ID <- substr(unit_site, 1, 8)  # Extract first 8 characters as unit_ID
unit_ID <- substr(file_df$unit_site, 1, 8)  # Extract first 8 characters as unit_ID
site_ID <- gsub("^[^_]+_", "", file_df$unit_site)
file_df$unit_ID <- substr(file_df$unit_site, 1, 8)  # Extract first 8 characters as unit_ID
file_df$site_ID <- gsub("^[^_]+_", "", file_df$unit_site)
View(file_df)
# Define audio file extensions
audio_exten <- c(".wav", ".mp3", ".zc", ".w4V")
# find rows that don't match the audio-file pattern
files_unmatched <- file_df[!grepl(paste(audio_exten, collapse = "|"), file_df$file_name), ]
# View the results
view(files_unmatched)
rm(list = ls())
# ------Load Libraries------
library(tidyverse)
library(tcltk)
library(tuneR)
# Find the file path to the files you want to index.
#   This will pop up a window for selection, you may have to minimize RStudio to see this window.
source_filepath <- tk_choose.dir()
# Find the directory where you'd like to save the modified output csv.
destination_filepath <- tk_choose.dir()
# Edit the file name within the "" below to name the output csv. Leave the quotes and
# ".csv" in the output name.
output_CSV_name <-"Audio_file_tracking.csv"
device_manuf<-c("Wildlife Acoustics")
#list all the files
File_List<-list.files(path = source_filepath,full.names=TRUE,recursive=TRUE)
#count the number of files
num_file<-length(File_List)
#create a dataframe from the list
file_df <- data.frame(ID = 1:num_file, file_loc = File_List)
# Find the first filepath with the most subfolders, and print it in the console.
max_index <- str_count(file_df$file_loc, "/")%>%
which.max()
print(file_df[max_index,"file_loc"])
header_file_df<-c("disk","Client","Year","Unit_Site","file_name")
#Split the columns by "/" create a new dataframe with the edited column headers.
file_df<-separate(data = file_df, col = file_loc, into = c(header_file_df), sep = "/", remove = FALSE)
#view split columns:
view(file_df)
# Define audio file extensions
audio_exten <- c(".wav", ".mp3", ".zc", ".w4V")
# find rows that don't match the audio-file pattern
files_unmatched <- file_df[!grepl(paste(audio_exten, collapse = "|"), file_df$file_name), ]
# View the results
view(files_unmatched)
misplaced_audio<-files_unmatched %>%
select(-file_name) %>%
filter_all(any_vars(str_detect(., paste(audio_exten, collapse = "|"))))
view(misplaced_audio)
file_track <<- file_df %>%
filter_all(any_vars(str_detect(file_name, paste(audio_exten, collapse = "|"))))
view(file_track)
for (i in 1:nrow(file_track)) {
file_path <- file_track$file_loc[i]
# Wrap the readWave() function in a tryCatch block
tryCatch({
audio <- readWave(file_path)
file_info <- file.info(file_path)
# Sampling frequency
sampling_frequency <- audio@samp.rate
# Duration in seconds
duration <- length(audio@left) / audio@samp.rate
#file size in bytes
file_size_bytes <- file_info$size
# Assign values to new columns
file_track$sampling_frequency[i] <- sampling_frequency
file_track$duration_s[i] <- duration
file_track$file_size_mb[i] <- file_size_bytes/(1024*1024)
#describe progress in the console
cat("Processed file", i, "of", nrow(file_track), "files\n")
}, error = function(e) {
# Handle errors
cat("Error processing file", i, ":", conditionMessage(e), "\n")
# Optionally, you can set default values for the columns to indicate the file couldn't be processed.
# For example, file_track$sampling_frequency[i] <- NA
#                          file_track$duration_s[i] <- NA
#                          file_track$file_size_mb[i] <- NA
}, warning = function(w) {
# Handle warnings
cat("Warning in processing file", i, ":", conditionMessage(w), "\n")
})
}
#view the updated file_track database
view(file_track)
#-----Pull the time out of the file name into a new column-----
# Create a function to find the "." before the file extension type
getLocation <- function(x) {
location <- nchar(x) - tail(unlist(gregexpr('\\.', x)), n=1) + 1
return(location)
}
# Pull the values that represent time in the file_name based off your specified manufacturer.
for (i in seq_along(file_track$file_name)) {
location <- getLocation(file_track$file_name[i])
if (device_manuf %in% c("Wildlife Acoustics", "Open Acoustic Devices", "Cornell")) {
file_track$time[i] <- str_sub(file_track$file_name[i], -6-location, -1-location)
} else if (device_manuf == "Titley Scientific") {
file_track$time[i] <- str_sub(file_track$file_name[i], -8-location, -1-location)
} else if (device_manuf == "Frontier Labs") {
file_track$time<-str_sub(file_track$file_name,10,15)
} else {
print("No date column created")
}}
# Check if "time" column exists and format time (HH:MM:SS).
if ("time" %in% colnames(file_track)) {
message("Time column created and formatted")
if (device_manuf == "Titley Scientific") {
file_track$time<-parse_time(file_track$time, "%H-%M-%S")
} else {
file_track$time<-parse_time(file_track$time, "%H%M%S")
}
} else {
message("Time column not created")
}
#-----Pull the date out of the file name into a new column-----
# Pull the values that represent date in the file_name based off your specified manufacturer.
for (i in seq_along(file_track$file_name)) {
location <- getLocation(file_track$file_name[i])
if (device_manuf %in% c("Wildlife Acoustics", "Open Acoustic Devices", "Cornell")) {
file_track$date[i] <- str_sub(file_track$file_name[i], -15-location, -8-location)
} else if (device_manuf == "Titley Scientific") {
file_track$date[i] <- str_sub(file_track$file_name[i], -19-location, -10-location)
} else if (device_manuf == "Frontier Labs") {
file_track$date<-str_sub(file_track$file_name,1,8)
} else {
}}
# Check if "Date" column exists and format date (YYYY-MM-DD)
if ("date" %in% colnames(file_track)) {
message("Date column created and formatted")
if (device_manuf == "Titley Scientific") {
file_track$date<-parse_date(file_track$date, "%Y-%m-%d")
} else {
file_track$date<-parse_date(file_track$date, "%Y%m%d")
}
} else {
message("Date column not created")
}
#review the final file_track database*
view(file_track)
#Export file_track to CSV for reference or further manipulation.
write.csv(file_track, file.path(destination_filepath,output_CSV_name), row.names=FALSE)
